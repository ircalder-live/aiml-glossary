AIML Glossary Project
=====================

![CI](https://github.com/ircalder-live/aiml-glossary/actions/workflows/ci.yml/badge.svg)
![Deploy](https://github.com/ircalder-live/aiml-glossary/actions/workflows/pages.yml/badge.svg)

ğŸ“– Overview
-----------
# AIML Glossary Workflow

This project uses a **URIâ€‘based workflow** for reproducibility and contributor clarity.
Instead of fragile filesystem paths, resources are referenced with logical URIs:

- `data:filename.json` â†’ maps to `repo_root/data/filename.json`
- `output:filename.csv` â†’ maps to `repo_root/output/filename.csv`
- `visualizations:filename.png` â†’ maps to `repo_root/visualizations/filename.png`

The resolver in `src/utils.py` ensures these URIs work consistently across local runs and CI/CD.

---

## Runbook

The main workflow is exercised through `notebooks/runbook.ipynb`.
Contributors should run the notebook cellâ€‘byâ€‘cell to generate and verify artifacts.

Expected steps:
1. **Generate outputs** â†’ `output/terms.csv`, `output/glossary_copy.json`
2. **Build link dictionary** â†’ `output/link_dictionary.json`
3. **Enrich glossary** â†’ `output/enriched_glossary.json`
4. **Graph clustering** â†’ `output/cluster_assignments.csv`, `output/graph_stats.json`, `visualizations/glossary_clusters.png`
5. **Semantic clustering** â†’ `output/semantic_cluster_assignments.csv`, `visualizations/semantic_clusters.png`
6. **Evaluate clusters** â†’ `output/ari_metrics.json`
7. **Coverage report** â†’ `output/coverage_report.json` with âœ…/âŒ markers

---

## Artifact Checklist

At the bottom of the runbook, a Markdown checklist is provided.
Contributors should confirm all expected artifacts are present and marked âœ… before committing.

---

## Quick Start

```bash
# Run the notebook end-to-end
jupyter nbconvert --execute --to notebook notebooks/runbook.ipynb --output notebooks/runbook_executed.ipynb

âš¡ Quick Start
--------------
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
2. Generate glossary outputs:
    make outputs
3. Run full clustering analysis (graph + semantic + evaluation):
    make cluster-analysis

Repository structure

aiml-glossary-project/
â”œâ”€â”€ data/                # Raw and processed data
â”‚   â”œâ”€â”€ aiml_glossary.json
â”‚   â””â”€â”€ link_dictionary.json
â”œâ”€â”€ src/                 # Source code for pipeline
â”‚   â”œâ”€â”€ generate_outputs.py       # Generate Markdown/XHTML glossary and coverage report
â”‚   â”œâ”€â”€ convert_glossary.py       # Convert Markdown glossary to JSON
â”‚   â”œâ”€â”€ cluster_analysis.py       # Graph-based clustering (Louvain)
â”‚   â”œâ”€â”€ semantic_clustering.py    # Definition-based clustering (TF-IDF + KMeans)
â”‚   â””â”€â”€ evaluate_clusters.py      # Compare clustering methods (ARI) and dashboard plots
â”œâ”€â”€ output/              # Generated outputs
â”‚   â”œâ”€â”€ glossary.md
â”‚   â”œâ”€â”€ glossary.xhtml
â”‚   â”œâ”€â”€ coverage_report.txt
â”‚   â”œâ”€â”€ cluster_assignments.csv
â”‚   â”œâ”€â”€ semantic_clusters.csv
â”‚   â””â”€â”€ ari_metrics.json
â”œâ”€â”€ visualizations/      # Saved plots
â”‚   â”œâ”€â”€ glossary_clusters.png
â”‚   â”œâ”€â”€ semantic_clusters.png
â”‚   â”œâ”€â”€ ari_trend.png
â”‚   â””â”€â”€ ari_bar.png
â”œâ”€â”€ experiments/         # MLflow artifacts (auto-created)
â”‚   â””â”€â”€ mlruns/
â”œâ”€â”€ notebooks/           # Optional Jupyter notebooks
â”‚   â””â”€â”€ glossary_analysis.ipynb
|   â””â”€â”€ runbook.ipynb
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Makefile             # Workflow automation
â””â”€â”€ README.txt           # Project overview

Instructions (bash)
1. Install dependencies
    pip install -r requirements.txt
2. Generate glossary outputs
    make outputs
Produces:
    output/glossary.md
    output/glossary.xhtml
    output/coverage_report.txt
3. Run clustering analysis
    make cluster-analysis
Runs graph clustering, semantic clustering, and evaluation. Produces:
    output/cluster_assignments.csv
    output/semantic_clusters.csv
    output/ari_metrics.json
    Plots in visualizations/
4. Lint and test
    make lint
    make test
5. Clean outputs
    make clean
    make clean-all
All runs are logged under the experiment name "AIML Glossary Analysis".

Parameters, metrics, and artifacts are tracked automatically.

To view results, start the MLflow UI:
    mlflow ui --backend-store-uri experiments/mlruns
Then open http://127.0.0.1:5000 in your browser.

Outputs: Generate enriched glossary in Markdown/XHTML.

Graph clustering: Louvain algorithm groups terms by connectivity.

Semantic clustering: TF-IDF + KMeans groups terms by definition similarity.

Evaluation: Adjusted Rand Index compares graph vs semantic clusters.

Dashboard: ARI trend and bar charts visualize consistency across runs.


---

This version is complete, consistent with your updated scripts and Makefile, and beginnerâ€‘friendly with Quick Start instructions.
