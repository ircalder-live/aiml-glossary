{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916d1ab4",
   "metadata": {},
   "source": [
    "# AIML Glossary Analysis Notebook\n",
    "\n",
    "This notebook explores the AIML glossary as a dataset:\n",
    "- Load glossary JSON\n",
    "- Build a graph of terms and links\n",
    "- Compute basic metrics\n",
    "- Run clustering analysis\n",
    "- Visualize clusters\n",
    "- Log results to MLflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53866f",
   "metadata": {},
   "source": [
    "## Cell 1: Setup, data loading, graph clustering (Louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fde478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed (uncomment if running fresh)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import community  # python-louvain\n",
    "\n",
    "# Set MLflow experiment and run name\n",
    "mlflow.set_experiment(\"AIML Glossary Analysis\")\n",
    "RUN_NAME = os.getenv(\"RUN_NAME\", f\"notebook-{os.getenv('GITHUB_SHA', 'local')}\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "# Load Glossary Data\n",
    "with open(\"data/aiml_glossary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    glossary = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(glossary)} glossary entries.\")\n",
    "glossary[0]  # peek at first entry\n",
    "\n",
    "# Build a Graph of Terms\n",
    "G = nx.Graph()\n",
    "for entry in glossary:\n",
    "    term = entry.get(\"term\")\n",
    "    if not term:\n",
    "        continue\n",
    "    G.add_node(term)\n",
    "    for rel in entry.get(\"related_terms\", []):\n",
    "        rel_term = rel[\"label\"] if isinstance(rel, dict) else rel\n",
    "        if rel_term:\n",
    "            G.add_edge(term, rel_term)\n",
    "    for tag in entry.get(\"tags\", []):\n",
    "        tag_term = tag[\"label\"] if isinstance(tag, dict) else tag\n",
    "        if tag_term:\n",
    "            G.add_edge(term, tag_term)\n",
    "\n",
    "print(f\"Graph has {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
    "\n",
    "# Compute Metrics\n",
    "num_terms = len(G.nodes)\n",
    "num_links = len(G.edges)\n",
    "avg_degree = sum(dict(G.degree()).values()) / num_terms if num_terms > 0 else 0\n",
    "\n",
    "print(\"Number of terms:\", num_terms)\n",
    "print(\"Number of links:\", num_links)\n",
    "print(\"Average degree:\", avg_degree)\n",
    "\n",
    "# Clustering Analysis (Louvain)\n",
    "partition = community.best_partition(G)\n",
    "num_clusters = len(set(partition.values()))\n",
    "largest_cluster_size = max(pd.Series(list(partition.values())).value_counts())\n",
    "modularity = community.modularity(partition, G)\n",
    "\n",
    "print(\"Clusters found:\", num_clusters)\n",
    "print(\"Largest cluster size:\", largest_cluster_size)\n",
    "print(\"Modularity:\", modularity)\n",
    "\n",
    "# Save Cluster Assignments\n",
    "cluster_df = pd.DataFrame(list(partition.items()), columns=[\"term\", \"cluster_id\"])\n",
    "cluster_df.to_csv(\"output/cluster_assignments.csv\", index=False)\n",
    "\n",
    "# Visualize Clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw_networkx_nodes(G, pos, node_color=[partition[n] for n in G.nodes], cmap=plt.cm.Set3)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "plt.title(\"Glossary Clusters (Louvain)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualizations/glossary_clusters.png\")\n",
    "plt.show()\n",
    "\n",
    "# Log Results to MLflow\n",
    "with mlflow.start_run(run_name=f\"{RUN_NAME}-graph\"):\n",
    "    mlflow.log_param(\"num_terms\", num_terms)\n",
    "    mlflow.log_param(\"num_links\", num_links)\n",
    "    mlflow.log_metric(\"avg_degree\", avg_degree)\n",
    "    mlflow.log_metric(\"num_clusters\", num_clusters)\n",
    "    mlflow.log_metric(\"largest_cluster_size\", largest_cluster_size)\n",
    "    mlflow.log_metric(\"modularity\", modularity)\n",
    "    mlflow.log_artifact(\"data/aiml_glossary.json\")\n",
    "    mlflow.log_artifact(\"output/cluster_assignments.csv\")\n",
    "    mlflow.log_artifact(\"visualizations/glossary_clusters.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5ede3",
   "metadata": {},
   "source": [
    "## Cell 2: Semantic Clustering (TF-IDF + KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Clustering with TF-IDF + KMeans\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "# Collect definitions and terms\n",
    "definitions = [entry.get(\"definition\", \"\") or \"\" for entry in glossary]\n",
    "terms = [entry.get(\"term\", \"\") or \"\" for entry in glossary]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(definitions)\n",
    "\n",
    "# Choose number of clusters (default 5, override via env RUN_K)\n",
    "k = int(os.getenv(\"RUN_K\", 5))\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Build DataFrame of assignments\n",
    "semantic_df = pd.DataFrame({\"term\": terms, \"cluster_id\": clusters})\n",
    "semantic_df.to_csv(\"output/semantic_clusters.csv\", index=False)\n",
    "semantic_df.head()\n",
    "\n",
    "# Inspect Cluster Contents (show first 15 terms per cluster)\n",
    "for cluster_id in range(k):\n",
    "    cluster_terms = semantic_df[semantic_df[\"cluster_id\"] == cluster_id][\"term\"].tolist()\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_terms)} terms):\")\n",
    "    print(\", \".join(cluster_terms[:15]))\n",
    "\n",
    "# Visualize Semantic Clusters (2D Projection)\n",
    "try:\n",
    "    X_2d = PCA(n_components=2, random_state=42).fit_transform(X.toarray())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=clusters, cmap=\"Set3\", alpha=0.7, s=20)\n",
    "    plt.title(\"Semantic Clusters of Glossary Terms (TF-IDF + KMeans)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/semantic_clusters.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Note: PCA visualization skipped due to: {e}\")\n",
    "\n",
    "# Log Semantic Clustering Results to MLflow\n",
    "with mlflow.start_run(run_name=f\"{RUN_NAME}-semantic\"):\n",
    "    mlflow.log_param(\"algo\", \"tfidf-kmeans\")\n",
    "    mlflow.log_param(\"k\", k)\n",
    "    mlflow.log_param(\"num_terms\", len(terms))\n",
    "    mlflow.log_metric(\"inertia\", float(kmeans.inertia_))\n",
    "    mlflow.log_artifact(\"output/semantic_clusters.csv\")\n",
    "    if os.path.exists(\"visualizations/semantic_clusters.png\"):\n",
    "        mlflow.log_artifact(\"visualizations/semantic_clusters.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33621b",
   "metadata": {},
   "source": [
    "✅ Outcome\n",
    "Glossary terms are grouped by semantic similarity of definitions.\n",
    "\n",
    "A 2D scatter plot shows clusters visually.\n",
    "\n",
    "MLflow logs the semantic cluster assignments as an artifact, alongside the graph‑based clustering runs.\n",
    "\n",
    "This gives two complementary views:\n",
    "\n",
    "Graph‑based clustering → connectivity of terms via tags/related terms.\n",
    "\n",
    "Semantic clustering → similarity of definitions via text embeddings.\n",
    "\n",
    "Together, they provide a richer picture of how the glossary is structured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222a791",
   "metadata": {},
   "source": [
    "## Cell 3: Cluster Comparison (ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Comparison (Graph vs Semantic Clusters)\n",
    "import os\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "# Align terms from both clustering methods\n",
    "graph_clusters = []\n",
    "semantic_clusters = []\n",
    "\n",
    "for term in terms:\n",
    "    # Graph cluster assignment\n",
    "    graph_clusters.append(partition.get(term, -1))\n",
    "    # Semantic cluster assignment\n",
    "    match = semantic_df.loc[semantic_df[\"term\"] == term, \"cluster_id\"]\n",
    "    semantic_clusters.append(int(match.values[0]) if not match.empty else -1)\n",
    "\n",
    "# Compute Adjusted Rand Index\n",
    "ari = adjusted_rand_score(graph_clusters, semantic_clusters)\n",
    "print(\"Adjusted Rand Index (Graph vs Semantic):\", ari)\n",
    "\n",
    "# Save ARI metric to JSON\n",
    "import json\n",
    "with open(\"output/ari_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"adjusted_rand_index\": ari}, f, indent=2)\n",
    "\n",
    "# Log Comparison Metric to MLflow\n",
    "with mlflow.start_run(run_name=f\"{RUN_NAME}-comparison\"):\n",
    "    mlflow.log_metric(\"adjusted_rand_index\", ari)\n",
    "    mlflow.log_artifact(\"output/cluster_assignments.csv\")\n",
    "    mlflow.log_artifact(\"output/semantic_clusters.csv\")\n",
    "    mlflow.log_artifact(\"output/ari_metrics.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05405af3",
   "metadata": {},
   "source": [
    "✅ Outcome\n",
    "Adjusted Rand Index (ARI) ranges from:\n",
    "\n",
    "1.0 → perfect agreement between clustering methods.\n",
    "\n",
    "0.0 → random agreement.\n",
    "\n",
    "Negative values → worse than random.\n",
    "\n",
    "This shows how much overlap exists between graph‑based clusters (connectivity) and semantic clusters (definition similarity).\n",
    "\n",
    "MLflow will log the ARI metric alongside your other experiments, to track consistency across runs.\n",
    "\n",
    "This comparison is a quantitative way to evaluate whether glossary terms that are strongly linked also share semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33651d5b",
   "metadata": {},
   "source": [
    "## Cell 4: Dashboard Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c951188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard Visualizations for ARI Metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "# Collect ARI Metrics Across Runs from MLflow\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"AIML Glossary Analysis\")\n",
    "\n",
    "runs = client.search_runs([experiment.experiment_id]) if experiment else []\n",
    "ari_data = []\n",
    "for run in runs:\n",
    "    metrics = run.data.metrics\n",
    "    if \"adjusted_rand_index\" in metrics:\n",
    "        ari_data.append({\n",
    "            \"run_id\": run.info.run_id,\n",
    "            \"run_name\": run.data.tags.get(\"mlflow.runName\", \"\"),\n",
    "            \"timestamp\": run.info.start_time,\n",
    "            \"adjusted_rand_index\": metrics[\"adjusted_rand_index\"]\n",
    "        })\n",
    "\n",
    "ari_df = pd.DataFrame(ari_data)\n",
    "if not ari_df.empty:\n",
    "    ari_df[\"timestamp\"] = pd.to_datetime(ari_df[\"timestamp\"], unit=\"ms\")\n",
    "    ari_df.sort_values(\"timestamp\", inplace=True)\n",
    "\n",
    "    # Line chart: ARI over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ari_df[\"timestamp\"], ari_df[\"adjusted_rand_index\"], marker=\"o\", linestyle=\"-\")\n",
    "    plt.title(\"Adjusted Rand Index Across Glossary Runs\")\n",
    "    plt.xlabel(\"Run Timestamp\")\n",
    "    plt.ylabel(\"Adjusted Rand Index\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de606aa",
   "metadata": {},
   "source": [
    "✅ Outcome\n",
    "Line chart → shows ARI values over time, to indicate trends in consistency between graph and semantic clustering.\n",
    "\n",
    "Bar chart → compares ARI values across individual runs, useful for spotting which glossary versions align better.\n",
    "\n",
    "Both charts can be saved as artifacts (ari_trend.png, ari_bar.png) and logged to MLflow for dashboard‑style tracking.\n",
    "\n",
    "This gives a visual dashboard inside Jupyter and MLflow, so this glossary project operates as an experiment pipeline.\n",
    "\n",
    "This completes the loop: glossary → clustering → comparison → dashboard → MLflow logging."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
